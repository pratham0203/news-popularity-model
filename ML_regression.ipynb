{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error: 407415263.094958\n",
      "Mean absolute error: 4151614.019545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,  r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "from statistics import median, mean\n",
    "from math import sqrt\n",
    "import pickle\n",
    "\n",
    "#weights file\n",
    "filename = 'finalized_model.sav'\n",
    "\n",
    "dataset = \"OnlineNewsPopularityRegression.csv\"\n",
    "\n",
    "#better choice than np.loadtxt\n",
    "df = pd.read_csv(dataset)\n",
    "#first 2 columns are meta data, not used for training\n",
    "df = df.iloc[:, 2:]\n",
    "\n",
    "n_samples, n_features = df.shape\n",
    "\n",
    "#Scaling/standardizing data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X=df.drop('shares', axis=1)\n",
    "X=X.drop('n_non_stop_words', axis=1)\n",
    "X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "y=df['shares']\n",
    "\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "arr = svd.fit_transform(X)\n",
    "arr = pd.DataFrame(arr)\n",
    "new_X = pd.concat([X, arr], axis=1)\n",
    "new_X[new_X.columns] = scaler.fit_transform(new_X[new_X.columns])\n",
    "\n",
    "\n",
    "#train_X, test_X, train_y, test_y = train_test_split(new_X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "\n",
    "train = df.iloc[:30000, :]\n",
    "train_X = train.iloc[:, :58]\n",
    "train_y = train.iloc[:, 58:]\n",
    "\n",
    "test = df.iloc[30000:, :]\n",
    "test_X = test.iloc[:, :58]\n",
    "\n",
    "test_y = test.iloc[:, 58:]\n",
    "\n",
    "predictions = np.zeros((test_y.shape))\n",
    "#model_fitting\n",
    "#All models\n",
    "bay_rid = BayesianRidge()\n",
    "bay_rid.fit(train_X, train_y)\n",
    "bay_predictions = bay_rid.predict(test_X)\n",
    "bay_predictions = bay_predictions.reshape(9644,1)\n",
    "\n",
    "predictions += bay_predictions\n",
    "lasso = Lasso()\n",
    "lasso.fit(train_X, train_y)\n",
    "lasso_predictions = lasso.predict(test_X)\n",
    "lasso_predictions = lasso_predictions.reshape(9644,1)\n",
    "\n",
    "predictions += lasso_predictions\n",
    "\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(train_X, train_y)\n",
    "predictions += ridge.predict(test_X)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_X, train_y)\n",
    "predictions += lin_reg.predict(test_X)\n",
    "\n",
    "\n",
    "#model = RandomForestRegressor(n_estimators=50) #promising\n",
    "#print(model.feature_importances_)\n",
    "#threshold = 1/len(model.feature_importances_)\n",
    "\n",
    "# save the model to disk\n",
    "#pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# load the model from disk\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "result = model.score(test_X, test_y)\n",
    "print(result)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#predictions = model.predict(test_X)\n",
    "#print(max(predictions))\n",
    "\"\"\"\n",
    "keys = new_X.keys()\n",
    "count = 0\n",
    "for i in range(len(model.feature_importances_)):\n",
    "    val = model.feature_importances_[i]\n",
    "    if val > threshold:\n",
    "        count+=1\n",
    "        try:\n",
    "            print(keys[i])\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "        print(str(val))\n",
    "        #df = df.drop(keys[i], axis=1)\n",
    "\n",
    "print(count)\n",
    "\"\"\"\n",
    "#metrics\n",
    "predictions /= 4\n",
    "#print(predictions)\n",
    "print(\"Root mean squared error: %f\" % sqrt(mean_squared_error(test_y, predictions)))\n",
    "print(\"Mean absolute error: %f\" % mean_absolute_error(test_y, predictions))\n",
    "#predictions.to_csv(\"my_predictions.csv\")\n",
    "\n",
    "errors = []\n",
    "for i in range(0, len(predictions)):\n",
    "    errors.append(abs(test_y.iloc[i] - predictions[i]))\n",
    "    #print(\"Predicted: \" + str(predictions[i])+\"  Actual: \"+str(test_y.iloc[i]))\n",
    "\n",
    "#print(mean(list(errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(\"Before - error median: %.2f\" % median(errors))\n",
    "errors = sorted(errors)\n",
    "errors = errors[100:-100]\n",
    "print(mean(errors))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#dropping less important columns\n",
    "keys = df.keys()\n",
    "count = 0\n",
    "for i in range(len(model.feature_importances_)):\n",
    "    val = model.feature_importances_[i]\n",
    "    if val <= 0.001:\n",
    "        count+=1\n",
    "        #print(keys[i]+\" \"+str(val))\n",
    "        df = df.drop(keys[i], axis=1)\n",
    "\n",
    "#print(df.shape)\n",
    "#1/60 = 0.0167 assuming equally likely variables\n",
    "#feature importance of n_non_stop_words == 0.0 which is weird since it seems to be an imp feature\n",
    "\n",
    "X=df.drop(' shares', axis=1)\n",
    "X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "#print(X.iloc[0])\n",
    "#print(df.shape)\n",
    "y=df[' shares']\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "\n",
    "#model_fitting\n",
    "model = RandomForestRegressor(max_depth=10, random_state=0) #promising\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "predictions = model.predict(test_X)\n",
    "\n",
    "#metrics\n",
    "print(\"Mean squared error: %f\" % mean_squared_error(test_y, predictions))\n",
    "print(\"Mean absolute error: %f\" % mean_absolute_error(test_y, predictions))\n",
    "\n",
    "errors = []\n",
    "for i in range(0, len(predictions)):\n",
    "    errors.append(abs(test_y.iloc[i] - predictions[i]))\n",
    "    #print(\"Predicted: \" + str(predictions[i])+\"  Actual: \"+str(test_y.iloc[i]))\n",
    "\n",
    "print(errors)\n",
    "print(\"After - error median: %.2f\" % median(errors))\n",
    "\n",
    "median_data = median(errors)\n",
    "print(sorted(errors))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
